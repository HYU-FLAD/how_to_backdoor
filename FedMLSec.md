Table of Contents
-----------------


# Setup Python Environment
- Set the name of environment in both files: `environment.yml` and `Makefile`. The default name is `aba`, aka "all backdoor attacks" and then run following commands:
```
    make install
```

# Guideline for custome training (Atk vs Def)

## Data Customization
- [Data Loader](https://github.com/FedML-AI/FedML/blob/master/doc/en/simulation/user_guide/data_loader_customization.md)

## Datasets and Models Customization
- [Datasets and Models](https://github.com/FedML-AI/FedML/blob/master/doc/en/simulation/user_guide/datasets-and-models.md#datasets-and-models)
- [FedML Data](https://github.com/FedML-AI/FedML/tree/master/python/fedml/data)

## Attack Customization

## Defense Customization

## Training Customization

## Evaluation Customization

## Visualization Customization

## Result Customization

## Reference

# Source
- [FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and Federated LLMs](https://arxiv.org/pdf/2306.04959.pdf)
- [Attack and Defense of FedMLSecurity](https://github.com/FedML-AI/FedML/blob/master/python/fedml/core/security/readme.md)
- [fedMLSecurity_experiments](https://github.com/FedML-AI/FedML/tree/master/python/examples/security/fedMLSecurity_experiments)

